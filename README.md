
# ğŸ“š Local Chatbot Systemï½œæœ¬åœ°ç«¯ä¼æ¥­çŸ¥è­˜å•ç­”ç³»çµ±

æœ¬å°ˆæ¡ˆæ˜¯ä¸€å¥—åŸºæ–¼æœ¬åœ°éƒ¨ç½²çš„å¤§èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰èˆ‡èªæ„æª¢ç´¢æ¶æ§‹çš„ä¼æ¥­å…§éƒ¨å•ç­”åŸå‹ç³»çµ±ï¼Œæ”¯æ´ PDF æ–‡ä»¶ä¸Šå‚³ã€åµŒå…¥å‘é‡åº«å»ºç½®ã€è‡ªç„¶èªè¨€æå•èˆ‡å¤šè¼ªå°è©±è¨˜æ†¶ã€‚ä½¿ç”¨è€…å¯é€éç°¡æ˜“ UI èˆ‡å…§éƒ¨æ–‡ä»¶äº’å‹•ï¼Œæœ‰æ•ˆé™ä½é‡è¤‡æ€§å•ç­”èˆ‡è¡Œæ”¿è² æ“”ã€‚

This project is a prototype of a local enterprise knowledge chatbot system powered by an on-premise LLM and semantic retrieval. It allows users to upload internal PDF documents, build a vector store, and ask questions in natural language with multi-turn memory, aiming to reduce repetitive queries and streamline internal communication.

---

## ğŸŒŸ åŠŸèƒ½ Features

- ğŸ“„ æ”¯æ´å¤šä»½ PDF æ–‡ä»¶ä¸Šå‚³èˆ‡å‘é‡åµŒå…¥  
  Support multiple PDF uploads with vector embedding
- ğŸ§¹ è‡ªå‹•é€²è¡Œæ–‡å­—æ¸…ç†èˆ‡èªæ„åˆ‡ç‰‡ï¼ˆChunkingï¼‰  
  Automatic text cleaning and semantic chunking
- ğŸ§  æœ¬åœ°ç«¯ LLMï¼ˆOllama + Gemma3 æ¨¡å‹ï¼‰  
  On-device LLM (Ollama + Gemma3)
- ğŸ” çµåˆ LangChain Retriever é€²è¡Œèªæ„æª¢ç´¢  
  Integrated LangChain Retriever for semantic search
- ğŸ’¬ å¤šè¼ªå°è©±è¨˜æ†¶ï¼ˆè¨˜æ†¶æœ€è¿‘ä¸‰è¼ªå°è©±ï¼‰  
  Multi-turn memory (last 3 turns)
- ğŸ–¥ï¸ Streamlit UI æä¾›ç°¡æ˜“å•ç­”ä»‹é¢  
  Streamlit-based user interface for chatbot interaction
- ğŸ§¾ æ”¯æ´ç¹é«”ä¸­æ–‡è‡ªç„¶èªè¨€å•ç­”  
  Traditional Chinese natural language Q&A
- ğŸ“‚ æ¸¬è©¦æ–‡ä»¶èˆ‡å›ç­”ç¤ºæ„åœ–é™„æ–¼å°ˆæ¡ˆä¸­  
  Demo documents and screenshot included

---

## ğŸ“ å°ˆæ¡ˆçµæ§‹ Project Structure

```
Local_Chatbot_System/
â”œâ”€â”€ main.py                   # ä¸»ç¨‹å¼ Main script
â”œâ”€â”€ answer_example.jpg        # å›ç­”ç•«é¢ç¤ºæ„åœ– Screenshot
â”œâ”€â”€ requirements.txt          # å¥—ä»¶éœ€æ±‚ Required packages
â””â”€â”€ test_doc/                 # æ¸¬è©¦ç”¨ PDF è³‡æ–™å¤¾ Test documents
    â”œâ”€â”€ HR_QA.pdf
    â””â”€â”€ Finance_QA.pdf
```

---

## ğŸ›  ä½¿ç”¨æŠ€è¡“ Tech Stack

- **LLM**ï¼šOllamaï¼ˆGemma3ï¼‰  
  Ollama (Gemma3 local model)
- **èªæ„åµŒå…¥æ¨¡å‹**ï¼šnomic-embed-text  
  nomic-embed-text (embedding for Chinese)
- **å‘é‡è³‡æ–™åº«**ï¼šChromaï¼ˆè¨˜æ†¶é«”ä¸­ï¼‰  
  Chroma (in-memory vector store)
- **æ¡†æ¶æ•´åˆ**ï¼šLangChain  
  LangChain for agent orchestration
- **UIä»‹é¢**ï¼šStreamlit  
  Streamlit interface
- **è¨˜æ†¶æ¨¡çµ„**ï¼šConversationBufferWindowMemory  
  Memory module: window memory (3 rounds)

---

## ğŸš€ åŸ·è¡Œæ–¹å¼ How to Run

### 1ï¸âƒ£ å®‰è£å¿…è¦ Python å¥—ä»¶ Install required packages

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ å®‰è£ Ollama ä¸¦ä¸‹è¼‰æ¨¡å‹ Install Ollama & Models

è«‹è‡³ Ollama å®˜æ–¹ç¶²ç«™å®‰è£ï¼š  
Visit https://ollama.com/ to install Ollama

ä¸‹è¼‰æ‰€éœ€æ¨¡å‹ï¼š  
Download the required models:

```bash
ollama pull nomic-embed-text
ollama pull gemma3:4b
```

### 3ï¸âƒ£ å•Ÿå‹•ç³»çµ± Launch the app

```bash
streamlit run main.py
```

---

## ğŸ”® æœªä¾†è¦åŠƒ Roadmap

- [ ] åŠ å…¥ SQLite å„²å­˜å‘é‡åº«ï¼Œæ”¯æ´è·¨æ¬¡å•Ÿå‹•  
      Add SQLite backend to persist vector store
- [ ] æ”¯æ´å¤šæ©Ÿå™¨äººåˆ†é¡ï¼ˆHR/è²¡å‹™/ITï¼‰  
      Multiple bot modes for HR/Finance/IT
- [ ] æ•´åˆ Docker + Ubuntu GPU éƒ¨ç½²æ¶æ§‹  
      Docker + GPU deployment for enterprise use
- [ ] åŠ å…¥åŸæ–‡æ®µè½å¼•ç”¨èˆ‡å›ç­”ä¾†æºæ¨™ç¤º  
      Display cited sources from PDF text
- [ ] å¯¦ä½œçŸ¥è­˜ä¸Šå‚³èˆ‡æ¬Šé™ç®¡ç†ä»‹é¢  
      Upload interface with access control

---

## ğŸ™‹â€â™€ï¸ ä½œè€… Author

**é„­å®›ç‘œï¼ˆWinnie Jhengï¼‰**  

